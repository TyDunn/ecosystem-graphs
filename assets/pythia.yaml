---

- type: model
  name: Pythia
  organization: Eleuther AI
  description: A suite of 16 LLMs all trained on public data seen in the exact same
    order and ranging in size from 70M to 12B parameters
  created_date: 2023-05-31
  url: https://arxiv.org/pdf/2304.01373.pdf
  model_card: https://huggingface.co/EleutherAI/pythia-6.9b
  modality: natural language text
  analysis: Evaluated on a variety of NLP benchmarks and found to perform similarly
    to OPT and BLOOM models.
  size: 1.0B parameters
  dependencies: [public Pythia dataset]
  training_emissions: ''
  training_time: ''
  training_hardware: 64 A100 GPUs
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: https://huggingface.co/EleutherAI/pythia-6.9b/discussions
